{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\georg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import kaggle\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing import Pipeline\n",
    "from darts.dataprocessing.transformers import Scaler, InvertibleMapper, StaticCovariatesTransformer\n",
    "from darts.dataprocessing.transformers.missing_values_filler import MissingValuesFiller\n",
    "from darts.metrics import rmsle\n",
    "from darts.models import LinearRegressionModel, LightGBMModel, XGBModel, CatBoostModel\n",
    "from darts.models.filtering.moving_average_filter import MovingAverageFilter\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "COLORS = list(sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"~/store-sales-time-series-forecasting/\"\n",
    "\n",
    "\n",
    "holiday_events = pd.read_csv(directory + 'holidays_events.csv', parse_dates=[\"date\"])\n",
    "oil = pd.read_csv(directory + 'oil.csv',parse_dates=[\"date\"])\n",
    "sample_submission = pd.read_csv(directory + 'sample_submission.csv')\n",
    "stores = pd.read_csv(directory + 'stores.csv')\n",
    "test = pd.read_csv(directory + 'test.csv',parse_dates=[\"date\"])\n",
    "train = pd.read_csv(directory + 'train.csv', parse_dates=[\"date\"])\n",
    "transactions = pd.read_csv(directory + 'transactions.csv',parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_family = train.family.nunique()\n",
    "num_store = train.store_nbr.nunique()\n",
    "num_ts = train.groupby([\"store_nbr\", \"family\"]).ngroups\n",
    "train_start = train.date.min().date()\n",
    "train_end = train.date.max().date()\n",
    "num_train_date = train.date.nunique()\n",
    "train_len = (train_end - train_start).days + 1\n",
    "test_start = test.date.min().date()\n",
    "test_end = test.date.max().date()\n",
    "num_test_date = test.date.nunique()\n",
    "test_len = (test_end - test_start).days + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex training data\n",
    "multi_idx = pd.MultiIndex.from_product(\n",
    "    [pd.date_range(train_start, train_end), train.store_nbr.unique(), train.family.unique()],\n",
    "    names=[\"date\", \"store_nbr\", \"family\"],\n",
    ")\n",
    "train = train.set_index([\"date\", \"store_nbr\", \"family\"]).reindex(multi_idx).reset_index()\n",
    "\n",
    "# fill missing values with 0s\n",
    "train[[\"sales\", \"onpromotion\"]] = train[[\"sales\", \"onpromotion\"]].fillna(0.)\n",
    "train.id = train.id.interpolate(method=\"linear\") # interpolate linearly as a filler for the 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dates = pd.date_range(train_start, train_end).difference(train.date.unique())\n",
    "missing_dates = missing_dates.strftime(\"%Y-%m-%d\").tolist()\n",
    "\n",
    "unique_dp_count = train.groupby([\"store_nbr\", \"family\"]).date.count().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "missing_oil_dates = pd.date_range(train_start, test_end).difference(oil.date)\n",
    "num_missing_oil_dates = len(missing_oil_dates)\n",
    "num_wknd_missing = (missing_oil_dates.weekday >= 5).sum()\n",
    "total_num_wknd = (pd.date_range(train_start, test_end).weekday >= 5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = oil.rename(columns={\"dcoilwtico\": \"oil\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex oil data\n",
    "oil = oil.merge(\n",
    "    pd.DataFrame({\"date\": pd.date_range(train_start, test_end)}),\n",
    "    on=\"date\",\n",
    "    how=\"outer\",\n",
    ").sort_values(\"date\", ignore_index=True)\n",
    "\n",
    "# fill missing values using linear interpolation\n",
    "oil['oil'] = oil['oil'].interpolate(method=\"linear\", limit_direction=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_zero_sales = (train.groupby([\"date\", \"store_nbr\"]).sales.sum().eq(0)).sum()\n",
    "total_rec = num_store * train_len\n",
    "curr_rec = len(transactions.index)\n",
    "missing_rec = total_rec - curr_rec - num_zero_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales = train.groupby([\"date\", \"store_nbr\"]).sales.sum().reset_index()\n",
    "\n",
    "# reindex transaction data\n",
    "transactions = transactions.merge(\n",
    "    store_sales,\n",
    "    on=[\"date\", \"store_nbr\"],\n",
    "    how=\"outer\",\n",
    ").sort_values([\"date\", \"store_nbr\"], ignore_index=True)\n",
    "\n",
    "# fill missing values with 0s for days with zero sales\n",
    "transactions.loc[transactions.sales.eq(0), \"transactions\"] = 0.\n",
    "\n",
    "# fill remaining missing values using linear interpolation\n",
    "transactions['transaction'] = transactions.groupby(\"store_nbr\", group_keys=False).transactions.apply(\n",
    "    lambda x: x.interpolate(method=\"linear\", limit_direction=\"both\")\n",
    ")\n",
    "\n",
    "transactions = transactions.drop(columns=['transaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>transactions</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91147</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>50</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>16879.121004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91148</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>51</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>20154.559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91149</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>52</td>\n",
       "      <td>2255.0</td>\n",
       "      <td>18600.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91150</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>53</td>\n",
       "      <td>932.0</td>\n",
       "      <td>8208.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91151</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>802.0</td>\n",
       "      <td>12666.858000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91152 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  store_nbr  transactions         sales\n",
       "0     2013-01-01          1           0.0      0.000000\n",
       "1     2013-01-01          2           0.0      0.000000\n",
       "2     2013-01-01          3           0.0      0.000000\n",
       "3     2013-01-01          4           0.0      0.000000\n",
       "4     2013-01-01          5           0.0      0.000000\n",
       "...          ...        ...           ...           ...\n",
       "91147 2017-08-15         50        2804.0  16879.121004\n",
       "91148 2017-08-15         51        1573.0  20154.559000\n",
       "91149 2017-08-15         52        2255.0  18600.046000\n",
       "91150 2017-08-15         53         932.0   8208.189000\n",
       "91151 2017-08-15         54         802.0  12666.858000\n",
       "\n",
       "[91152 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>93.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>92.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>93.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>93.146667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>46.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>46.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>46.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>45.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>47.260000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1704 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date        oil\n",
       "0    2013-01-01  93.140000\n",
       "1    2013-01-02  93.140000\n",
       "2    2013-01-03  92.970000\n",
       "3    2013-01-04  93.120000\n",
       "4    2013-01-05  93.146667\n",
       "...         ...        ...\n",
       "1699 2017-08-27  46.816667\n",
       "1700 2017-08-28  46.400000\n",
       "1701 2017-08-29  46.460000\n",
       "1702 2017-08-30  45.960000\n",
       "1703 2017-08-31  47.260000\n",
       "\n",
       "[1704 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>transactions</th>\n",
       "      <th>sales</th>\n",
       "      <th>oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91147</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>50</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>16879.121004</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91148</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>51</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>20154.559000</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91149</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>52</td>\n",
       "      <td>2255.0</td>\n",
       "      <td>18600.046000</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91150</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>53</td>\n",
       "      <td>932.0</td>\n",
       "      <td>8208.189000</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91151</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>802.0</td>\n",
       "      <td>12666.858000</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91152 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  store_nbr  transactions         sales    oil\n",
       "0     2013-01-01          1           0.0      0.000000  93.14\n",
       "1     2013-01-01          2           0.0      0.000000  93.14\n",
       "2     2013-01-01          3           0.0      0.000000  93.14\n",
       "3     2013-01-01          4           0.0      0.000000  93.14\n",
       "4     2013-01-01          5           0.0      0.000000  93.14\n",
       "...          ...        ...           ...           ...    ...\n",
       "91147 2017-08-15         50        2804.0  16879.121004  47.57\n",
       "91148 2017-08-15         51        1573.0  20154.559000  47.57\n",
       "91149 2017-08-15         52        2255.0  18600.046000  47.57\n",
       "91150 2017-08-15         53         932.0   8208.189000  47.57\n",
       "91151 2017-08-15         54         802.0  12666.858000  47.57\n",
       "\n",
       "[91152 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df = transactions.merge(\n",
    "    oil,\n",
    "    on = ['date'],\n",
    "    how = 'left'\n",
    ").sort_values([\"date\", \"store_nbr\"], ignore_index=True)\n",
    "\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.merge(\n",
    "    oil,\n",
    "    on = ['date'],\n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "test_df = test.merge(\n",
    "    oil,\n",
    "    on = ['date'],\n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "data = pd.concat(\n",
    "    [train_df, test_df], axis=0, ignore_index=True,\n",
    ").sort_values([\"date\", \"store_nbr\", \"family\"], ignore_index=True)\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lgb(train_df):\n",
    "    \n",
    "    prediction_df = train_df[train_df['date'] >= '2017-08-16' ].copy()\n",
    "    train_df = train_df[train_df['date'] < '2017-08-16' ].copy()\n",
    "\n",
    "    # Set the index for the dataframes\n",
    "    train_df.set_index(['id', 'date'], inplace=True)\n",
    "    prediction_df.set_index(['id', 'date'], inplace=True)\n",
    "    \n",
    "        # Prepare training and prediction data\n",
    "    X_train = train_df.drop(columns=['sales'])\n",
    "    y_train = train_df['sales']\n",
    "    X_pred = prediction_df.drop(columns=['sales'])\n",
    "\n",
    "    # Create a LightGBM dataset for training\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    # Define and train the LightGBM model\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "    }\n",
    "\n",
    "    num_round = 100  # Adjust the number of boosting rounds as needed\n",
    "    bst = lgb.train(params, train_data, num_round)\n",
    "\n",
    "    # Make predictions for the prediction set\n",
    "    predictions = bst.predict(X_pred, num_iteration=bst.best_iteration)\n",
    "\n",
    "    # Create a dataframe with the predictions\n",
    "    prediction_df['sales'] = predictions\n",
    "\n",
    "    train_df.reset_index(inplace=True)\n",
    "    prediction_df.reset_index(inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return prediction_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_encode_non_numeric_cols(df):\n",
    "    \"\"\"\n",
    "    Encodes non-numeric columns in a Pandas DataFrame using LabelEncoder.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame to encode.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame with the non-numeric columns encoded.\n",
    "        dict: A dictionary with original to encoded mappings for each non-numeric column.\n",
    "    \"\"\"\n",
    "    # get the list of non-numeric column names\n",
    "    non_numeric_cols = df.select_dtypes(exclude=[np.number, bool, 'category', 'datetime']).columns.tolist()\n",
    "    \n",
    "    # if there are no non-numeric columns, return the original DataFrame\n",
    "    if not non_numeric_cols:\n",
    "        return df, {}\n",
    "    \n",
    "    # create a new DataFrame to store the encoded columns\n",
    "    encoded_df = df.copy()\n",
    "    \n",
    "    # dictionary to store the encodings\n",
    "    encoding_dict = {}\n",
    "    \n",
    "    # iterate over each non-numeric column and encode its values\n",
    "    for col in non_numeric_cols:\n",
    "        encoder = LabelEncoder()\n",
    "        encoded_df[col] = encoder.fit_transform(df[col])\n",
    "        \n",
    "        # store the original to encoded mappings in the dictionary\n",
    "        encoding_dict[col] = dict(zip(encoder.transform(encoder.classes_), encoder.classes_ ))\n",
    "    \n",
    "    return encoded_df, encoding_dict\n",
    "\n",
    "# Example usage:\n",
    "# encoded_df, encodings = label_encode_non_numeric_cols(original_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 319\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 6.086778\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 0.110266\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 320\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 3.706918\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 431\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 2380.139613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 310\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 0.070629\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 405\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 462.238301\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 8.350634\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 405\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 1069.875472\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 471\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 707.474427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 392\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 264.506785\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 343\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 171.014306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 343\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 154.400208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 3768.021929\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 318\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 21.532901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 315\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 1.135137\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 335\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 20.421834\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 326\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 16.682794\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 0.456392\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 356\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 175.780499\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 328\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 7.143661\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 6.021173\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 320\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 7.165109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 331\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 84.985958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 317\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 2.922141\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 367\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 341.039894\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 361\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 269.791678\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 317\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 3.911971\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 326\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 6.172196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 359\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 349.701646\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 96.540889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 560\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 1346.154606\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 2.954581\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 318\n",
      "[LightGBM] [Info] Number of data points in the train set: 91152, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 22.110671\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data, ecoding_dict = label_encode_non_numeric_cols(data)\n",
    "\n",
    "predictions = data.groupby('family', group_keys=False).apply(apply_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictions.sort_values('id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
